{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the folder containing your Excel files\n",
    "data_folder = \"Data\"\n",
    "\n",
    "# Define the column names\n",
    "col_names = ['Case ID', 'Suspect Product Active Ingredients', 'Reason for Use', 'Reactions', 'Serious', 'Outcomes', 'Sex', 'Patient Age', 'Patient Weight']\n",
    "\n",
    "# Initialize an empty DataFrame to store the combined data\n",
    "combined_data = pd.DataFrame(columns=col_names)\n",
    "\n",
    "# Iterate over all Excel files in the folder\n",
    "for file in os.listdir(data_folder):\n",
    "    if file.endswith(\".xlsx\"):  # Check if the file is an Excel file\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "        # Read the Excel file and add it to the combined DataFrame\n",
    "        data = pd.read_excel(file_path, usecols=col_names)  # Load only the specified columns\n",
    "        combined_data = pd.concat([combined_data, data], ignore_index=True)\n",
    "\n",
    "# Display the combined dataset\n",
    "#print(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Case ID', 'Suspect Product Active Ingredients', 'Reactions',  'Serious', 'Sex', 'Patient Age', 'Patient Weight']\n",
    "\n",
    "#df = data[selected_columns]\n",
    "df = combined_data[selected_columns]\n",
    "\n",
    "#df.head()\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Suspect Product Active Ingredients'] = df['Suspect Product Active Ingredients'].str.split(';')\n",
    "df_split_temp = df.explode('Suspect Product Active Ingredients', ignore_index=True)\n",
    "\n",
    "df_split_temp['Reactions'] = df_split_temp['Reactions'].str.split(';')\n",
    "df_split = df_split_temp.explode('Reactions', ignore_index = True)\n",
    "\n",
    "#df_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi = pd.get_dummies(df_split, columns = ['Suspect Product Active Ingredients', 'Reactions'], prefix=['Product', 'Reaction'], prefix_sep='_')\n",
    "reactions = [col for col in df_multi.columns if col.startswith(\"Reaction_\")]\n",
    "df_reaction = df_multi[reactions]\n",
    "df_multi = df_multi.groupby('Case ID').max().reset_index()\n",
    "\n",
    "columns_to_exclude = ['Case ID', 'Suspect Product Active Ingredients', 'Reactions', 'Serious', 'Sex', 'Patient Age', 'Patient Weight']\n",
    "\n",
    "columns_to_convert = [col for col in df_multi.columns if col.startswith(\"Product_\") or col.startswith(\"Reaction_\")] #not in columns_to_exclude]\n",
    "\n",
    "df_multi[columns_to_convert] = df_multi[columns_to_convert].astype(int)\n",
    "\n",
    "df_final = df_multi\n",
    "#print(df_multi.columns)\n",
    "#print(df_final)\n",
    "\n",
    "#df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = df_multi.copy()\n",
    "#print(df_encoded.columns)\n",
    "#print(df_split['Patient Age'])\n",
    "df_encoded['Patient Age'] = df_encoded['Patient Age'].astype(str)\n",
    "df_encoded['Patient Age'] = df_encoded['Patient Age'].str.replace(r'\\D+', '', regex=True)\n",
    "df_encoded['Patient Age'] = pd.to_numeric(df_encoded['Patient Age'], errors='coerce')  # Converts to numeric, sets invalid values to NaN\n",
    "\n",
    "df_encoded['Patient Weight'] = df_encoded['Patient Weight'].replace('Not Specified', \"0 KG\")\n",
    "df_encoded['Patient Weight'] = df_encoded['Patient Weight'].astype(str)\n",
    "df_encoded['Patient Weight'] = df_encoded['Patient Weight'].str.replace(r'[^\\d.]', '', regex=True)\n",
    "df_encoded['Patient Weight'] = pd.to_numeric(df_encoded['Patient Weight'], errors='coerce')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#df_encoded['Suspect Product Active Ingredients'] = label_encoder.fit_transform(df_encoded['Suspect Product Active Ingredients'])\n",
    "df_encoded['Sex'] = label_encoder.fit_transform(df_encoded['Sex'])\n",
    "df_encoded['Serious'] = label_encoder.fit_transform(df_encoded['Serious'])\n",
    "#print(df_encoded.isnull().sum())\n",
    "df_encoded.dropna(inplace=True)\n",
    "#print(df_encoded.isnull().sum())\n",
    "#df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum columns that start with \"Reaction_\"\n",
    "reaction_columns = df_encoded.filter(like=\"Reaction_\", axis=1)\n",
    "column_sums = reaction_columns.sum(axis=0)\n",
    "\n",
    "#print(len(reaction_columns.columns))\n",
    "# Set the threshold\n",
    "threshold = 50 #300\n",
    "\n",
    "# Filter column names with sums greater than the threshold\n",
    "columns_above_threshold = column_sums[column_sums > threshold].index.tolist()\n",
    "\n",
    "#print(columns_above_threshold)\n",
    "#print(len(columns_above_threshold))\n",
    "\n",
    "filtered_df = df_encoded[df_encoded[columns_above_threshold].sum(axis=1) > 0]\n",
    "\n",
    "# Print the number of rows before and after filtering\n",
    "#print(f\"Number of rows before filtering: {df_encoded.shape[0]}\")\n",
    "#print(f\"Number of rows after removing all-zero rows: {filtered_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_exclude = ['Case ID', 'Suspect Product Active Ingredients', 'Serious' ,'Reactions']\n",
    "\n",
    "feature_cols = [col for col in df_encoded.columns if col not in cols_to_exclude and not col.startswith(\"Reaction_\")]\n",
    "\n",
    "print(feature_cols)\n",
    "print(len(feature_cols))\n",
    "\n",
    "X_serious = df_encoded[feature_cols]\n",
    "Y_serious = df_encoded.Serious\n",
    "\n",
    "# Reaction Predictor\n",
    "\n",
    "feat_cols = [\"Serious\"]\n",
    "feat_cols.extend(feature_cols)\n",
    "\n",
    "print(feat_cols)\n",
    "print(len(feat_cols))\n",
    "\n",
    "predict_cols = []#[\"Serious\"]\n",
    "reaction_cols = columns_above_threshold #[col for col in df_encoded.columns if col.startswith(\"Reaction_\")]\n",
    "predict_cols.extend(reaction_cols)\n",
    "\n",
    "print(predict_cols)\n",
    "print(len(predict_cols))\n",
    "\n",
    "df_filtered = df_encoded[df_encoded[predict_cols].sum(axis=1) > 0]\n",
    "\n",
    "X_reaction = df_filtered[feat_cols]\n",
    "Y_reaction = df_filtered[predict_cols]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
