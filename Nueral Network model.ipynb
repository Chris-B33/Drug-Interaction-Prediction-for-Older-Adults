{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Load your dataset\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_excel('Line Listing(dxjZy).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Case ID', 'Suspect Product Active Ingredients', 'Serious', 'Sex', 'Patient Age', 'Patient Weight']\n",
    "\n",
    "df = data[selected_columns]\n",
    "\n",
    "df.head()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Suspect Product Active Ingredients'] = df['Suspect Product Active Ingredients'].str.split(';')\n",
    "df_split = df.explode('Suspect Product Active Ingredients', ignore_index=True)\n",
    "\n",
    "df_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df_split['Serious'].value_counts()\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_split.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi = pd.get_dummies(df_split, columns=['Suspect Product Active Ingredients'], prefix='', prefix_sep='')\n",
    "\n",
    "df_multi = df_multi.groupby('Case ID').max().reset_index()\n",
    "\n",
    "# Columns to exclude from conversion\n",
    "columns_to_exclude = ['Case ID', 'Suspect Product Active Ingredients', 'Serious', 'Sex', 'Patient Age', 'Patient Weight']\n",
    "\n",
    "# Get the columns to convert by excluding the specified ones\n",
    "columns_to_convert = [col for col in df_multi.columns if col not in columns_to_exclude]\n",
    "\n",
    "# Convert only the desired columns to 0/1\n",
    "df_multi[columns_to_convert] = df_multi[columns_to_convert].astype(int)\n",
    "\n",
    "df_final = df_multi\n",
    "print(df_multi.columns)\n",
    "print(df_final)\n",
    "\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_multi.columns)\n",
    "#df_encoded = df_split\n",
    "df_encoded = df_multi.copy()\n",
    "print(df_encoded.columns)\n",
    "#print(df_split['Patient Age'])\n",
    "df_encoded['Patient Age'] = df_encoded['Patient Age'].astype(str)\n",
    "df_encoded['Patient Age'] = df_encoded['Patient Age'].str.replace(r'\\D+', '', regex=True)\n",
    "df_encoded['Patient Age'] = pd.to_numeric(df_encoded['Patient Age'], errors='coerce')  # Converts to numeric, sets invalid values to NaN\n",
    "\n",
    "df_encoded['Patient Weight'] = df_encoded['Patient Weight'].replace('Not Specified', \"0 KG\")\n",
    "df_encoded['Patient Weight'] = df_encoded['Patient Weight'].astype(str)\n",
    "#df_encoded['Patient Weight'] = df_encoded['Patient Weight'].str.replace(r'\\D+', '', regex=True)\n",
    "df_encoded['Patient Weight'] = df_encoded['Patient Weight'].str.replace(r'[^\\d.]', '', regex=True)\n",
    "df_encoded['Patient Weight'] = pd.to_numeric(df_encoded['Patient Weight'], errors='coerce')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#df_encoded['Suspect Product Active Ingredients'] = label_encoder.fit_transform(df_encoded['Suspect Product Active Ingredients'])\n",
    "df_encoded['Sex'] = label_encoder.fit_transform(df_encoded['Sex'])\n",
    "df_encoded['Serious'] = label_encoder.fit_transform(df_encoded['Serious'])\n",
    "print(df_encoded.isnull().sum())\n",
    "df_encoded.dropna(inplace=True)\n",
    "print(df_encoded.isnull().sum())\n",
    "df_encoded.head()\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df_encoded['Serious'].value_counts()\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['Suspect Product Active Ingredients', 'Sex', 'Patient Age', 'Patient Weight']\n",
    "\n",
    "# Columns to exclude from conversion\n",
    "columns_to_exclude = ['Case ID', 'Suspect Product Active Ingredients']\n",
    "\n",
    "# Get the columns to convert by excluding the specified ones\n",
    "feature_cols = [col for col in df_encoded.columns if col not in columns_to_exclude]\n",
    "print(feature_cols)\n",
    "\n",
    "X = df_encoded[feature_cols]\n",
    "y = df_encoded.Serious\n",
    "#X = df_split[feature_cols]\n",
    "#Y = df_split.Serious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='linear')  # Adjust activation for specific reaction types\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test MAE: {mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
